FROM nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04

# Build arg for GPU architectures - specify which CUDA compute capabilities to compile for
# Common values:
#   7.0  - Tesla V100
#   7.5  - RTX 2060, 2070, 2080, Titan RTX
#   8.0  - A100, A800 (Ampere data center)
#   8.6  - RTX 3060, 3070, 3080, 3090 (Ampere consumer)
#   8.9  - RTX 4070, 4080, 4090 (Ada Lovelace)
#   9.0  - H100, H800 (Hopper data center)
#   12.0 - RTX 5070, 5080, 5090 (Blackwell) - Note: sm_120 architecture
#
# Examples:
#   RTX 3060: --build-arg CUDA_ARCHITECTURES="8.6"
#   RTX 4090: --build-arg CUDA_ARCHITECTURES="8.9"
#   Multiple: --build-arg CUDA_ARCHITECTURES="8.0;8.6;8.9"
#
# Note: Including 8.9 or 9.0 may cause compilation issues on some setups
# Default includes 8.0 and 8.6 for broad Ampere compatibility
ARG CUDA_ARCHITECTURES="8.0;8.6"

ENV DEBIAN_FRONTEND=noninteractive

# Install system dependencies
RUN apt update && \
    apt install -y \
    python3 python3-pip git wget curl cmake ninja-build \
    libgl1 libglib2.0-0 ffmpeg aria2 && \
    apt clean

WORKDIR /workspace

COPY requirements.txt .

# Upgrade pip first
RUN pip install --upgrade pip setuptools wheel

# Install requirements if exists
RUN pip install -r requirements.txt

# Install PyTorch with CUDA support
RUN pip install --extra-index-url https://download.pytorch.org/whl/cu124 \
    torch==2.6.0+cu124 torchvision==0.21.0+cu124

# Install huggingface_hub for model downloads
RUN pip install "huggingface_hub[hf_transfer]"

# Install SageAttention from git (patch GPU detection)
ENV TORCH_CUDA_ARCH_LIST="${CUDA_ARCHITECTURES}"
ENV FORCE_CUDA="1"
ENV MAX_JOBS="1"

COPY <<EOF /tmp/patch_setup.py
import os
with open('setup.py', 'r') as f:
    content = f.read()

# Get architectures from environment variable
arch_list = os.environ.get('TORCH_CUDA_ARCH_LIST')
arch_set = '{' + ', '.join([f'"{arch}"' for arch in arch_list.split(';')]) + '}'

# Replace the GPU detection section
old_section = '''compute_capabilities = set()
device_count = torch.cuda.device_count()
for i in range(device_count):
    major, minor = torch.cuda.get_device_capability(i)
    if major < 8:
        warnings.warn(f"skipping GPU {i} with compute capability {major}.{minor}")
        continue
    compute_capabilities.add(f"{major}.{minor}")'''

new_section = 'compute_capabilities = ' + arch_set + '''
print(f"Manually set compute capabilities: {compute_capabilities}")'''

content = content.replace(old_section, new_section)

with open('setup.py', 'w') as f:
    f.write(content)
EOF

RUN git clone https://github.com/thu-ml/SageAttention.git /tmp/sageattention && \
    cd /tmp/sageattention && \
    python3 /tmp/patch_setup.py && \
    pip install --no-build-isolation . && \
    ln -sf /bin/bash /bin/sh

RUN useradd -u 1000 -ms /bin/bash user

RUN chown -R user:user /workspace

RUN mkdir /home/user/.cache && \
    chown -R user:user /home/user/.cache

# Copy and setup hfd.sh (HuggingFace downloader script)
COPY hfd.sh /usr/local/bin/hfd.sh
RUN chmod +x /usr/local/bin/hfd.sh

# Create model directories
RUN mkdir -p /workspace/ckpts/pose \
             /workspace/ckpts/xlm-roberta-large \
             /workspace/ckpts/umt5-xxl

# Download SteadyDancer main model (quanto int8)
RUN hfd.sh DeepBeepMeep/Wan2.1 \
      --include "wan2.1_steadydancer_14B_quanto_mbf16_int8.safetensors" \
      --local-dir /tmp/hfd_steadydancer && \
    mv /tmp/hfd_steadydancer/wan2.1_steadydancer_14B_quanto_mbf16_int8.safetensors /workspace/ckpts/ && \
    rm -rf /tmp/hfd_steadydancer

# Download shared VAE and projection models
RUN hfd.sh DeepBeepMeep/Wan2.1 \
      --include "Wan2.1_VAE.safetensors" \
      --include "fantasy_proj_model.safetensors" \
      --include "Wan2.1_VAE_upscale2x_imageonly_real_v1.safetensors" \
      --local-dir /tmp/hfd_wan21_shared && \
    mv /tmp/hfd_wan21_shared/Wan2.1_VAE.safetensors /workspace/ckpts/ && \
    mv /tmp/hfd_wan21_shared/fantasy_proj_model.safetensors /workspace/ckpts/ && \
    mv /tmp/hfd_wan21_shared/Wan2.1_VAE_upscale2x_imageonly_real_v1.safetensors /workspace/ckpts/ && \
    rm -rf /tmp/hfd_wan21_shared

# Download pose detection models (for SteadyDancer)
RUN hfd.sh DeepBeepMeep/Wan2.1 \
      --include "pose/dw-ll_ucoco_384.onnx" \
      --include "pose/yolox_l.onnx" \
      --local-dir /tmp/hfd_pose && \
    mv /tmp/hfd_pose/pose/dw-ll_ucoco_384.onnx /workspace/ckpts/pose/ && \
    mv /tmp/hfd_pose/pose/yolox_l.onnx /workspace/ckpts/pose/ && \
    rm -rf /tmp/hfd_pose

# Download text encoder models (xlm-roberta-large)
RUN hfd.sh DeepBeepMeep/Wan2.1 \
      --include "xlm-roberta-large/models_clip_open-clip-xlm-roberta-large-vit-huge-14-bf16.safetensors" \
      --include "xlm-roberta-large/sentencepiece.bpe.model" \
      --include "xlm-roberta-large/special_tokens_map.json" \
      --include "xlm-roberta-large/tokenizer.json" \
      --include "xlm-roberta-large/tokenizer_config.json" \
      --local-dir /tmp/hfd_xlm && \
    mkdir -p /workspace/ckpts/xlm-roberta-large && \
    mv /tmp/hfd_xlm/xlm-roberta-large/* /workspace/ckpts/xlm-roberta-large/ && \
    rm -rf /tmp/hfd_xlm

# Download text encoder models (umt5-xxl)
RUN hfd.sh DeepBeepMeep/Wan2.1 \
      --include "umt5-xxl/models_t5_umt5-xxl-enc-bf16.safetensors" \
      --include "umt5-xxl/special_tokens_map.json" \
      --include "umt5-xxl/spiece.model" \
      --include "umt5-xxl/tokenizer.json" \
      --include "umt5-xxl/tokenizer_config.json" \
      --local-dir /tmp/hfd_umt5 && \
    mkdir -p /workspace/ckpts/umt5-xxl && \
    mv /tmp/hfd_umt5/umt5-xxl/* /workspace/ckpts/umt5-xxl/ && \
    rm -rf /tmp/hfd_umt5

# Verify all required model files are downloaded
RUN echo "Verifying SteadyDancer model files..." && \
    test -f /workspace/ckpts/wan2.1_steadydancer_14B_quanto_mbf16_int8.safetensors && echo "✓ SteadyDancer main model found" || (echo "ERROR: SteadyDancer main model not found" && exit 1) && \
    test -f /workspace/ckpts/Wan2.1_VAE.safetensors && echo "✓ VAE model found" || (echo "ERROR: VAE model not found" && exit 1) && \
    test -f /workspace/ckpts/fantasy_proj_model.safetensors && echo "✓ Fantasy projection model found" || (echo "ERROR: Fantasy projection model not found" && exit 1) && \
    test -f /workspace/ckpts/pose/dw-ll_ucoco_384.onnx && echo "✓ DWPose model found" || (echo "ERROR: DWPose model not found" && exit 1) && \
    test -f /workspace/ckpts/pose/yolox_l.onnx && echo "✓ YOLOX detection model found" || (echo "ERROR: YOLOX detection model not found" && exit 1) && \
    test -f /workspace/ckpts/xlm-roberta-large/models_clip_open-clip-xlm-roberta-large-vit-huge-14-bf16.safetensors && echo "✓ XLM-RoBERTa model found" || (echo "ERROR: XLM-RoBERTa model not found" && exit 1) && \
    test -f /workspace/ckpts/umt5-xxl/models_t5_umt5-xxl-enc-bf16.safetensors && echo "✓ UMT5-XXL model found" || (echo "ERROR: UMT5-XXL model not found" && exit 1) && \
    echo "✓ All SteadyDancer model files verified successfully"

# Set ownership of model directories
RUN chown -R user:user /workspace/ckpts

COPY entrypoint.sh /workspace/entrypoint.sh

ENTRYPOINT ["/workspace/entrypoint.sh"]
