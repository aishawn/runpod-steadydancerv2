import runpod
from runpod.serverless.utils import rp_upload
import os
import sys
import base64
import json
import uuid
import logging
import tempfile
import traceback
from pathlib import Path
from PIL import Image
import torch
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# ç¡®ä¿å·¥ä½œç›®å½•æ­£ç¡®ï¼ˆRunPod å®¹å™¨ä¸­åº”è¯¥æ˜¯ /workspaceï¼‰
workspace_dir = Path("/workspace")
if workspace_dir.exists() and workspace_dir.is_dir():
    os.chdir(workspace_dir)
    logger_workspace = logging.getLogger("workspace")
    logger_workspace.info(f"å·¥ä½œç›®å½•è®¾ç½®ä¸º: {os.getcwd()}")
else:
    # å¦‚æœ /workspace ä¸å­˜åœ¨ï¼Œä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•
    os.chdir(project_root)
    logger_workspace = logging.getLogger("workspace")
    logger_workspace.info(f"å·¥ä½œç›®å½•è®¾ç½®ä¸º: {os.getcwd()}")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¯¼å…¥ Wan2GP ç›¸å…³æ¨¡å—
# æ³¨æ„ï¼šéœ€è¦å…ˆåˆå§‹åŒ– wgp.py çš„å…¨å±€å˜é‡
os.environ["GRADIO_LANG"] = "en"
os.environ["GRADIO_ANALYTICS_ENABLED"] = "False"

# å¯¼å…¥ wgp æ¨¡å—ä»¥åˆå§‹åŒ–å…¨å±€å˜é‡
# æ³¨æ„ï¼šwgp.py åœ¨å¯¼å…¥æ—¶ä¼šæ‰§è¡Œåˆå§‹åŒ–ä»£ç ï¼ŒåŒ…æ‹¬è§£æå‚æ•°å’ŒåŠ è½½é…ç½®
import wgp

# ç­‰å¾… wgp æ¨¡å—åˆå§‹åŒ–å®Œæˆ
import time
time.sleep(0.1)  # ç»™åˆå§‹åŒ–ä¸€ç‚¹æ—¶é—´

# ä» wgp å¯¼å…¥å¿…è¦çš„å‡½æ•°å’Œå˜é‡
from wgp import (
    load_models, get_model_def, get_base_model_type, get_model_handler,
    get_model_filename, get_local_model_filename, download_models,
    transformer_quantization, transformer_dtype_policy, server_config,
    model_types_handlers, models_def, args
)
from shared.utils.utils import convert_image_to_tensor, save_video, convert_tensor_to_image
from shared.utils import files_locator as fl

# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹
wan_model = None
offloadobj = None
transformer_type = None

def to_nearest_multiple_of_16(value):
    """å°†å€¼è°ƒæ•´ä¸º 16 çš„å€æ•°"""
    try:
        numeric_value = float(value)
    except Exception:
        raise Exception(f"width/height å€¼å¿…é¡»æ˜¯æ•°å­—: {value}")
    adjusted = int(round(numeric_value / 16.0) * 16)
    if adjusted < 16:
        adjusted = 16
    return adjusted

def process_input(input_data, temp_dir, output_filename, input_type):
    """å¤„ç†è¾“å…¥æ•°æ®ï¼ˆè·¯å¾„ã€URL æˆ– base64ï¼‰"""
    if input_type == "path":
        logger.info(f"ğŸ“ è·¯å¾„è¾“å…¥å¤„ç†: {input_data}")
        if not os.path.exists(input_data):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {input_data}")
        return input_data
    elif input_type == "url":
        logger.info(f"ğŸŒ URL è¾“å…¥å¤„ç†: {input_data}")
        os.makedirs(temp_dir, exist_ok=True)
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        import urllib.request
        urllib.request.urlretrieve(input_data, file_path)
        return file_path
    elif input_type == "base64":
        logger.info(f"ğŸ”¢ Base64 è¾“å…¥å¤„ç†")
        return save_base64_to_file(input_data, temp_dir, output_filename)
    else:
        raise Exception(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {input_type}")

def save_base64_to_file(base64_data, temp_dir, output_filename):
    """å°† Base64 æ•°æ®ä¿å­˜ä¸ºæ–‡ä»¶"""
    try:
        # å¤„ç† data URI æ ¼å¼ (data:image/jpeg;base64,...)
        if ',' in base64_data:
            base64_data = base64_data.split(',')[1]
        
        decoded_data = base64.b64decode(base64_data)
        os.makedirs(temp_dir, exist_ok=True)
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        with open(file_path, 'wb') as f:
            f.write(decoded_data)
        logger.info(f"âœ… Base64 è¾“å…¥å·²ä¿å­˜åˆ°: {file_path}")
        return file_path
    except Exception as e:
        logger.error(f"âŒ Base64 è§£ç å¤±è´¥: {e}")
        raise Exception(f"Base64 è§£ç å¤±è´¥: {e}")

def load_video_frames(video_path, max_frames=None):
    """åŠ è½½è§†é¢‘å¸§ä¸º tensor"""
    try:
        import cv2
    except ImportError:
        raise ImportError("éœ€è¦å®‰è£… opencv-python: pip install opencv-python")
    
    cap = cv2.VideoCapture(video_path)
    frames = []
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if max_frames and len(frames) >= max_frames:
            break
        
        # è½¬æ¢ä¸º RGB
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame_pil = Image.fromarray(frame)
        frame_tensor = convert_image_to_tensor(frame_pil)
        frames.append(frame_tensor)
    
    cap.release()
    
    if not frames:
        raise ValueError(f"æ— æ³•ä»è§†é¢‘ä¸­è¯»å–å¸§: {video_path}")
    
    # å †å ä¸º (C, T, H, W)
    video_tensor = torch.stack(frames, dim=1)
    return video_tensor

def initialize_model(model_type="steadydancer"):
    """åˆå§‹åŒ– SteadyDancer æ¨¡å‹"""
    global wan_model, offloadobj, transformer_type
    
    if wan_model is not None and transformer_type == model_type:
        logger.info("æ¨¡å‹å·²åŠ è½½ï¼Œè·³è¿‡åˆå§‹åŒ–")
        return wan_model
    
    logger.info(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {model_type}")
    
    # ç¡®ä¿æ¨¡å‹å®šä¹‰å­˜åœ¨
    model_def = get_model_def(model_type)
    if model_def is None:
        raise ValueError(f"æ¨¡å‹ç±»å‹ '{model_type}' æœªæ‰¾åˆ°ã€‚è¯·ç¡®ä¿æ¨¡å‹å·²æ­£ç¡®é…ç½®ã€‚")
    
    # åŠ è½½æ¨¡å‹
    wan_model, offloadobj = load_models(model_type, override_profile=-1)
    transformer_type = model_type
    
    logger.info("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    return wan_model

def generate_steadydancer_video(
    image_start_path,
    video_guide_path,
    prompt,
    output_path,
    video_mask_path=None,
    negative_prompt="",
    resolution=(480, 832),
    video_length=81,
    seed=42,
    sampling_steps=50,
    guidance_scale=5.0,
    alt_guidance_scale=2.0,
    video_prompt_type="VA",
    image_prompt_type="S",
    device="cuda" if torch.cuda.is_available() else "cpu",
):
    """ä½¿ç”¨ SteadyDancer ç”Ÿæˆè§†é¢‘"""
    global wan_model
    
    logger.info(f"ğŸš€ å¼€å§‹ SteadyDancer è§†é¢‘ç”Ÿæˆ...")
    logger.info(f"   å‚è€ƒå›¾åƒ: {image_start_path}")
    logger.info(f"   æ§åˆ¶è§†é¢‘: {video_guide_path}")
    logger.info(f"   æç¤ºè¯: {prompt}")
    logger.info(f"   åˆ†è¾¨ç‡: {resolution[0]}x{resolution[1]}")
    logger.info(f"   è§†é¢‘é•¿åº¦: {video_length} å¸§")
    
    # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
    if wan_model is None:
        initialize_model("steadydancer")
    
    # è·å–æ¨¡å‹å¤„ç†å™¨
    base_model_type = get_base_model_type("steadydancer")
    model_handler = get_model_handler("steadydancer")
    
    # åŠ è½½è¾“å…¥
    logger.info("ğŸ“‚ åŠ è½½è¾“å…¥æ–‡ä»¶...")
    image_start = Image.open(image_start_path).convert("RGB")
    image_start_tensor = convert_image_to_tensor(image_start).to(device)
    
    # åŠ è½½æ§åˆ¶è§†é¢‘ï¼ˆåŸå§‹æ ¼å¼ï¼šC, T, H, Wï¼‰
    video_guide_raw = load_video_frames(video_guide_path).to(device)
    logger.info(f"   æ§åˆ¶è§†é¢‘å¸§æ•°: {video_guide_raw.shape[1]}")
    
    # åŠ è½½è§†é¢‘æ©ç ï¼ˆå¦‚æœæœ‰ï¼‰
    video_mask_raw = None
    if video_mask_path:
        video_mask_raw = load_video_frames(video_mask_path).to(device)
        logger.info(f"   è§†é¢‘æ©ç å¸§æ•°: {video_mask_raw.shape[1]}")
    
    logger.info("âœ… è¾“å…¥æ–‡ä»¶åŠ è½½å®Œæˆ")
    
    # SteadyDancer éœ€è¦å…ˆè¿›è¡Œå§¿æ€å¯¹é½é¢„å¤„ç†
    logger.info("ğŸ”„ è¿›è¡Œå§¿æ€å¯¹é½é¢„å¤„ç†...")
    
    # å‡†å¤‡ pre_video_guideï¼šå‚è€ƒå›¾åƒéœ€è¦æ·»åŠ æ—¶é—´ç»´åº¦ [C, 1, H, W]
    pre_video_guide = image_start_tensor.unsqueeze(1)  # [C, 1, H, W]
    
    # è½¬æ¢è§†é¢‘æ ¼å¼ï¼šcustom_preprocess_video_with_mask æœŸæœ›çš„æ ¼å¼
    # æ ¹æ® wgp.py çš„ custom_preprocess_video_with_mask å‡½æ•°ï¼š
    # - video_guide åº”è¯¥æ˜¯ [C, T, H, W] æ ¼å¼ï¼Œå€¼åœ¨ [-1, 1] èŒƒå›´
    # - å‡½æ•°å†…éƒ¨ä¼šè½¬æ¢ä¸º [T, H, W, C] å¹¶å½’ä¸€åŒ–
    # ä½†æˆ‘ä»¬ç›´æ¥è°ƒç”¨ custom_preprocessï¼Œå®ƒæœŸæœ›çš„æ ¼å¼æ˜¯ï¼š
    # - video_guide: [C, T, H, W] åœ¨ [-1, 1] èŒƒå›´ï¼ˆæ ¹æ®ä»£ç åˆ†æï¼‰
    # - pre_video_guide: [C, 1, H, W] åœ¨ [-1, 1] èŒƒå›´
    
    # è°ƒç”¨ custom_preprocess è¿›è¡Œå§¿æ€å¯¹é½
    # æ³¨æ„ï¼šcustom_preprocess å†…éƒ¨ä¼šå¤„ç†æ ¼å¼è½¬æ¢
    try:
        # æ ¹æ® wan_handler.pyï¼Œcustom_preprocess æœŸæœ›ï¼š
        # - pre_video_guide: [C, T, H, W] tensorï¼ˆå‚è€ƒå›¾åƒï¼‰
        # - video_guide: è§†é¢‘å¸§ï¼ˆæ ¼å¼ç”±å†…éƒ¨å¤„ç†ï¼‰
        # ä½†çœ‹ä»£ç ï¼Œcustom_preprocess å†…éƒ¨è°ƒç”¨ PoseAligner.alignï¼Œå®ƒæœŸæœ› frames æ˜¯ List[np.ndarray]
        # æ‰€ä»¥æˆ‘ä»¬éœ€è¦ä½¿ç”¨ custom_preprocess_video_with_mask å‡½æ•°
        
        from wgp import custom_preprocess_video_with_mask
        
        # å‡†å¤‡å‚æ•°ï¼šcustom_preprocess_video_with_mask æœŸæœ› video_guide æ˜¯ [C, T, H, W] åœ¨ [-1, 1]
        video_guide_for_preprocess = video_guide_raw  # å·²ç»æ˜¯ [C, T, H, W] åœ¨ [-1, 1]
        video_mask_for_preprocess = video_mask_raw  # å¦‚æœæœ‰ï¼Œä¹Ÿæ˜¯ [C, T, H, W] åœ¨ [-1, 1]
        
        # è°ƒç”¨é¢„å¤„ç†å‡½æ•°
        video_guide_processed, video_guide_processed2, video_mask_processed, video_mask_processed2 = custom_preprocess_video_with_mask(
            model_handler=model_handler,
            base_model_type=base_model_type,
            pre_video_guide=pre_video_guide,
            video_guide=video_guide_for_preprocess,
            video_mask=video_mask_for_preprocess,
            height=resolution[1],
            width=resolution[0],
            max_frames=video_guide_raw.shape[1],  # ä½¿ç”¨æ‰€æœ‰å¸§
            start_frame=0,
            fit_canvas=None,
            fit_crop=None,
            target_fps=16,
            block_size=16,
            expand_scale=0,
        )
        
        if video_guide_processed is None or video_guide_processed.numel() == 0:
            raise ValueError("å§¿æ€å¯¹é½é¢„å¤„ç†å¤±è´¥ï¼šè¿”å›çš„è§†é¢‘ä¸ºç©º")
        
        logger.info(f"âœ… å§¿æ€å¯¹é½å®Œæˆ: {video_guide_processed.shape}")
        
        # custom_preprocess_video_with_mask è¿”å›çš„æ ¼å¼åº”è¯¥æ˜¯ [C, T, H, W] åœ¨ [-1, 1]
        input_frames = video_guide_processed.to(device)
        input_frames2 = video_guide_processed2.to(device) if video_guide_processed2 is not None else None
        
    except Exception as e:
        logger.error(f"âŒ å§¿æ€å¯¹é½é¢„å¤„ç†å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise
    
    # å‡†å¤‡ input_videoï¼šå‚è€ƒå›¾åƒ [C, 1, H, W]
    input_video = pre_video_guide  # [C, 1, H, W]
    
    # ç”Ÿæˆè§†é¢‘
    logger.info("ğŸ¬ å¼€å§‹ç”Ÿæˆè§†é¢‘...")
    logger.info(f"   é‡‡æ ·æ­¥æ•°: {sampling_steps}")
    logger.info(f"   æ–‡æœ¬å¼•å¯¼: {guidance_scale}")
    logger.info(f"   æ¡ä»¶å¼•å¯¼: {alt_guidance_scale}")
    
    with torch.no_grad():
        samples = wan_model.generate(
            input_prompt=prompt,
            n_prompt=negative_prompt,
            image_start=None,  # SteadyDancer ä½¿ç”¨ input_video è€Œä¸æ˜¯ image_start
            input_video=input_video,  # å‚è€ƒå›¾åƒ [C, 1, H, W]
            input_frames=input_frames,  # å§¿æ€å¯¹é½åçš„æ§åˆ¶è§†é¢‘ [C, T, H, W]
            input_frames2=input_frames2,  # å¢å¼ºç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰
            height=resolution[1],
            width=resolution[0],
            frame_num=video_length,
            sampling_steps=sampling_steps,
            guide_scale=guidance_scale,
            alt_guide_scale=alt_guidance_scale,
            seed=seed,
            video_prompt_type=video_prompt_type,
            image_prompt_type=image_prompt_type,
        )
    
    logger.info("âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ")
    
    # ä¿å­˜è§†é¢‘
    logger.info(f"ğŸ’¾ ä¿å­˜è§†é¢‘åˆ°: {output_path}")
    save_video(samples, output_path, fps=16)
    logger.info("âœ… è§†é¢‘ä¿å­˜å®Œæˆ")
    
    return output_path

def handler(job):
    """
    RunPod handler for SteadyDancer video generation
    
    æ”¯æŒçš„è¾“å…¥å‚æ•°:
    - model_type: æ¨¡å‹ç±»å‹ (é»˜è®¤: "steadydancer")
    - prompt: æ–‡æœ¬æç¤ºè¯ (å¿…éœ€)
    - image_start: å‚è€ƒå›¾åƒ (è·¯å¾„ã€URL æˆ– base64) (å¿…éœ€)
    - video_guide: æ§åˆ¶è§†é¢‘ (è·¯å¾„ã€URL æˆ– base64) (å¿…éœ€)
    - video_mask: è§†é¢‘æ©ç  (è·¯å¾„ã€URL æˆ– base64) (å¯é€‰)
    - negative_prompt: è´Ÿé¢æç¤ºè¯ (å¯é€‰)
    - resolution: åˆ†è¾¨ç‡ï¼Œæ ¼å¼ "WIDTHxHEIGHT" (é»˜è®¤: "480x832")
    - video_length: è§†é¢‘é•¿åº¦/å¸§æ•° (é»˜è®¤: 81)
    - seed: éšæœºç§å­ (é»˜è®¤: 42)
    - sampling_steps: é‡‡æ ·æ­¥æ•° (é»˜è®¤: 50)
    - guidance_scale: æ–‡æœ¬å¼•å¯¼å¼ºåº¦ (é»˜è®¤: 5.0)
    - alt_guidance_scale: æ¡ä»¶å¼•å¯¼å¼ºåº¦/å§¿æ€å¼•å¯¼ (é»˜è®¤: 2.0)
    - video_prompt_type: è§†é¢‘æç¤ºç±»å‹ "V" æˆ– "VA" (é»˜è®¤: "VA")
    - image_prompt_type: å›¾åƒæç¤ºç±»å‹ (é»˜è®¤: "S")
    """
    job_input = job.get("input", {})
    
    # è®°å½•è¾“å…¥ï¼ˆæ’é™¤ base64 æ•°æ®ï¼‰
    log_input = {k: v for k, v in job_input.items() 
                 if k not in ["image_start", "video_guide", "video_mask"] or not isinstance(v, str) or len(v) < 100}
    logger.info(f"æ”¶åˆ°ä»»åŠ¡è¾“å…¥: {log_input}")
    
    task_id = f"task_{uuid.uuid4()}"
    temp_dir = os.path.join("/tmp", task_id)
    os.makedirs(temp_dir, exist_ok=True)
    
    try:
        # è·å–æ¨¡å‹ç±»å‹
        model_type = job_input.get("model_type", "steadydancer")
        if model_type != "steadydancer":
            logger.warning(f"æ¨¡å‹ç±»å‹ '{model_type}' ä¸æ˜¯ steadydancerï¼Œå°†ä½¿ç”¨ steadydancer")
            model_type = "steadydancer"
        
        # å¤„ç†å‚è€ƒå›¾åƒ
        image_start = None
        if "image_start" in job_input:
            image_input = job_input["image_start"]
            if isinstance(image_input, str):
                # åˆ¤æ–­æ˜¯è·¯å¾„ã€URL è¿˜æ˜¯ base64
                if image_input.startswith("http://") or image_input.startswith("https://"):
                    input_type = "url"
                elif image_input.startswith("data:") or len(image_input) > 100:
                    input_type = "base64"
                else:
                    input_type = "path"
            else:
                raise ValueError("image_start å¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼ˆè·¯å¾„ã€URL æˆ– base64ï¼‰")
            
            image_start = process_input(image_input, temp_dir, "input_image.jpg", input_type)
        else:
            raise ValueError("ç¼ºå°‘å¿…éœ€å‚æ•°: image_start (å‚è€ƒå›¾åƒ)")
        
        # å¤„ç†æ§åˆ¶è§†é¢‘
        video_guide = None
        if "video_guide" in job_input:
            video_input = job_input["video_guide"]
            if isinstance(video_input, str):
                if video_input.startswith("http://") or video_input.startswith("https://"):
                    input_type = "url"
                elif video_input.startswith("data:") or len(video_input) > 100:
                    input_type = "base64"
                else:
                    input_type = "path"
            else:
                raise ValueError("video_guide å¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼ˆè·¯å¾„ã€URL æˆ– base64ï¼‰")
            
            video_guide = process_input(video_input, temp_dir, "control_video.mp4", input_type)
        else:
            raise ValueError("ç¼ºå°‘å¿…éœ€å‚æ•°: video_guide (æ§åˆ¶è§†é¢‘)")
        
        # å¤„ç†è§†é¢‘æ©ç ï¼ˆå¯é€‰ï¼‰
        video_mask = None
        if "video_mask" in job_input and job_input["video_mask"]:
            mask_input = job_input["video_mask"]
            if isinstance(mask_input, str):
                if mask_input.startswith("http://") or mask_input.startswith("https://"):
                    input_type = "url"
                elif mask_input.startswith("data:") or len(mask_input) > 100:
                    input_type = "base64"
                else:
                    input_type = "path"
                video_mask = process_input(mask_input, temp_dir, "video_mask.mp4", input_type)
        
        # è·å–å…¶ä»–å‚æ•°
        prompt = job_input.get("prompt", "a person dancing")
        negative_prompt = job_input.get("negative_prompt", "")
        
        # è§£æåˆ†è¾¨ç‡
        resolution_str = job_input.get("resolution", "480x832")
        width, height = map(int, resolution_str.split('x'))
        width = to_nearest_multiple_of_16(width)
        height = to_nearest_multiple_of_16(height)
        resolution = (width, height)
        
        video_length = job_input.get("video_length", 81)
        seed = job_input.get("seed", 42)
        sampling_steps = job_input.get("sampling_steps", 50)
        guidance_scale = job_input.get("guidance_scale", 5.0)
        alt_guidance_scale = job_input.get("alt_guidance_scale", 2.0)
        video_prompt_type = job_input.get("video_prompt_type", "VA" if video_mask else "V")
        image_prompt_type = job_input.get("image_prompt_type", "S")
        
        # ç”Ÿæˆè¾“å‡ºè·¯å¾„
        output_path = os.path.join(temp_dir, "output_video.mp4")
        
        # ç”Ÿæˆè§†é¢‘
        generate_steadydancer_video(
            image_start_path=image_start,
            video_guide_path=video_guide,
            prompt=prompt,
            output_path=output_path,
            video_mask_path=video_mask,
            negative_prompt=negative_prompt,
            resolution=resolution,
            video_length=video_length,
            seed=seed,
            sampling_steps=sampling_steps,
            guidance_scale=guidance_scale,
            alt_guidance_scale=alt_guidance_scale,
            video_prompt_type=video_prompt_type,
            image_prompt_type=image_prompt_type,
        )
        
        # è¯»å–ç”Ÿæˆçš„è§†é¢‘å¹¶è½¬æ¢ä¸º base64
        logger.info("ğŸ“¤ å‡†å¤‡è¿”å›è§†é¢‘...")
        with open(output_path, 'rb') as f:
            video_data = f.read()
        
        video_base64 = base64.b64encode(video_data).decode('utf-8')
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        shutil.rmtree(temp_dir, ignore_errors=True)
        
        logger.info("âœ… ä»»åŠ¡å®Œæˆ")
        return {
            "video": video_base64,
            "format": "mp4",
            "resolution": f"{width}x{height}",
            "frames": video_length,
        }
        
    except Exception as e:
        error_message = str(e)
        error_traceback = traceback.format_exc()
        logger.error(f"âŒ ç”Ÿæˆå¤±è´¥: {error_message}")
        logger.error(f"é”™è¯¯è¯¦æƒ…:\n{error_traceback}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir, ignore_errors=True)
        
        return {
            "error": error_message,
            "traceback": error_traceback
        }

if __name__ == "__main__":
    runpod.serverless.start({"handler": handler})
